{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/Study_Log/blob/NLP/%5BHW24_Problem%5D_NaiveBayes_Classifier_%EC%9D%B4%EC%9E%AC%EC%98%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btDmoiRCRfMp"
      },
      "source": [
        "# **[HW24] NaiveBayes Classifier**\n",
        "1. Requirements\n",
        "2. Data Preprocessing\n",
        "3. Model Training\n",
        "4. Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3E1pbkSYSF"
      },
      "source": [
        "## 1. Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4THGPr9QIjQY"
      },
      "source": [
        "#### 1.1 필요한 패키지를 설치(install) 및 import 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKm6PwhiGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608ef4a8-7bd4-45c2-ab39-b12f84224408"
      },
      "source": [
        "# 한국어 전처리 라이브러리\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2srhF-lp4JxL"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "# POS(Part of Speech) tagger\n",
        "from konlpy import tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ-s9c77IVUA"
      },
      "source": [
        "#### 1.2 Train data 와 test data 를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCBnEQrfoL_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de72c160-f3be-4e9f-e996-b8059a567106"
      },
      "source": [
        "data = {}\n",
        "# training data. input text 와 정답 label (긍정(1), 부정(0)) 로 구성.\n",
        "\n",
        "data['train'] = [{'text': \"정말 재미있습니다. 추천합니다.\"},\n",
        "                {'text': \"기대했던 것보단 별로였네요.\"},\n",
        "                {'text': \"지루해서 다시 보고 싶다는 생각이 안 드네요.\"},\n",
        "                {'text': \"완전 최고입니다 ! 다시 보고 싶습니다.\"},\n",
        "                {'text': \"연기도 연출도 다 만족스러웠습니다.\"},\n",
        "                {'text': \"연기가 좀 별로였습니다.\"},\n",
        "                {'text': \"연출도 좋았고 배우분들 연기도 최고입니다.\"},\n",
        "                {'text': \"기념일에 방문했는데 연기도 연출도 다 좋았습니다.\"},\n",
        "                {'text': \"전반적으로 지루했습니다. 저는 별로였네요.\"},\n",
        "                {'text': \"CG에 조금 더 신경 썼으면 좋겠습니다.\"}\n",
        "                ]\n",
        "# test data\n",
        "data['test'] = [{'text': \"최고입니다. 또 보고 싶네요.\"},\n",
        "                {'text': \"별로였습니다. 되도록 보지 마세요.\"},\n",
        "                {'text': \"다른 분들께 추천드릴 수 있을 만큼 연출도 연기도 만족했습니다.\"},\n",
        "                {'text': \"연기가 좀 더 개선되었으면 좋겠습니다.\"}\n",
        "                ]\n",
        "\n",
        "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
        "test_labels = [1, 0, 1, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'기대했던 것보단 별로였네요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpgjbzqr6UR4"
      },
      "source": [
        "### 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKwnFBZqMXm-"
      },
      "source": [
        "#### 2.1 한글 형태소 분석기를 이용해서 주어진 데이터를 tokenize 합니다.\n",
        "\n",
        "오픈소스 형태소 분석기를 제공하는 파이썬 패키지 KoNLPy에서 제공하는 [꼬꼬마(Kkma) 형태소 분석기](https://konlpy.org/en/v0.5.2/api/konlpy.tag/#module-konlpy.tag._kkma)를 이용하여 tokenize 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEzeYDmPjNLl"
      },
      "source": [
        "# 형태소 분석기 선언\n",
        "morph_analyzer = tag.Kkma() # 형태소 단위로 tokenization 진행행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tftxirx_7sk7"
      },
      "source": [
        "# tokenization 함수 정의\n",
        "def tokenization(data, morph_analyzer):\n",
        "    '''\n",
        "    (input) data: list of data examples.\n",
        "            morph_analyzer: morphological analyzer.\n",
        "    (output) tokenized_data: list of tokenized data examples.\n",
        "    '''\n",
        "    tokenized_data = []\n",
        "\n",
        "    for example in tqdm(data):\n",
        "        tokens = morph_analyzer.morphs(example['text'])\n",
        "        tokenized_data.append(tokens)\n",
        "\n",
        "    return tokenized_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4VEZyFlCqi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab868f2-1466-4764-954a-7920e18c2101"
      },
      "source": [
        "# tokenization 함수를 이용한 데이터 tokenization\n",
        "tokenized_data = {}\n",
        "\n",
        "tokenized_data['train'] = tokenization(data['train'], morph_analyzer)\n",
        "tokenized_data['test'] = tokenization(data['test'], morph_analyzer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 29.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhn3uv2o2kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6a3d2b-2f84-4de6-804c-131c2b697c8d"
      },
      "source": [
        "# tokenized_data 확인\n",
        "tokenized_data['train']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['정말', '재미있', '습니다', '.', '추천', '하', 'ㅂ니다', '.'],\n",
              " ['기대', '하', '었', '더', 'ㄴ', '것', '보다', 'ㄴ', '별', '로', '이', '었', '네요', '.'],\n",
              " ['지루', '하', '어서', '다시', '보', '고', '싶', '다는', '생각', '이', '안', '들', '네요', '.'],\n",
              " ['완전', '최고', '이', 'ㅂ니다', '!', '다시', '보', '고', '싶', '습니다', '.'],\n",
              " ['연기', '도', '연출', '도', '다', '만족', '스럽', '었', '습니다', '.'],\n",
              " ['연기', '가', '좀', '별', '로', '이', '었', '습니다', '.'],\n",
              " ['연출', '도', '좋', '았', '고', '배우', '분', '들', '연기', '도', '최고', '이', 'ㅂ니다', '.'],\n",
              " ['기념일',\n",
              "  '에',\n",
              "  '방문',\n",
              "  '하',\n",
              "  '었',\n",
              "  '는데',\n",
              "  '연기',\n",
              "  '도',\n",
              "  '연출',\n",
              "  '도',\n",
              "  '다',\n",
              "  '좋',\n",
              "  '았',\n",
              "  '습니다',\n",
              "  '.'],\n",
              " ['전반적',\n",
              "  '으로',\n",
              "  '지루',\n",
              "  '하',\n",
              "  '었',\n",
              "  '습니다',\n",
              "  '.',\n",
              "  '저',\n",
              "  '는',\n",
              "  '별',\n",
              "  '로',\n",
              "  '이',\n",
              "  '었',\n",
              "  '네요',\n",
              "  '.'],\n",
              " ['CG', '에', '조금', '더', '신경', '쓰', '었', '으면', '좋', '겠', '습니다', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olCz4j6VS0KJ"
      },
      "source": [
        "#### 2.2 tokenization 결과를 이용해서 word to index dictionary 를 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2DXYDTTTChQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8265de6-5512-4cbb-c333-1e1cfa6d1daa"
      },
      "source": [
        "# train data의 tokenization 결과에서 unique token만 남긴 set으로 변환\n",
        "tokens = [token for i in range(len(tokenized_data['train'])) for token in tokenized_data['train'][i] ] # matrix to vector\n",
        "unique_train_tokens = set(tokens)\n",
        "\n",
        "# NaiveBayes Classifier의 input에 들어갈 word의 index를 반환해주는 dictionary를 생성\n",
        "word2index = defaultdict() # key: word, value: index of word\n",
        "idx = 0\n",
        "for token in tqdm(unique_train_tokens):\n",
        "    word2index[token] = idx\n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56/56 [00:00<00:00, 375809.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index # vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtBVeuo4eqxV",
        "outputId": "6dee8a39-8c24-4f76-c494-f0e906597763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'으로': 0,\n",
              "             '기념일': 1,\n",
              "             '보다': 2,\n",
              "             '조금': 3,\n",
              "             '추천': 4,\n",
              "             '겠': 5,\n",
              "             'ㅂ니다': 6,\n",
              "             '스럽': 7,\n",
              "             '으면': 8,\n",
              "             '기대': 9,\n",
              "             '별': 10,\n",
              "             '연기': 11,\n",
              "             '배우': 12,\n",
              "             '최고': 13,\n",
              "             '전반적': 14,\n",
              "             '.': 15,\n",
              "             '분': 16,\n",
              "             '방문': 17,\n",
              "             '가': 18,\n",
              "             'CG': 19,\n",
              "             '안': 20,\n",
              "             '었': 21,\n",
              "             '좋': 22,\n",
              "             '좀': 23,\n",
              "             '재미있': 24,\n",
              "             '고': 25,\n",
              "             '정말': 26,\n",
              "             '완전': 27,\n",
              "             '어서': 28,\n",
              "             '싶': 29,\n",
              "             '지루': 30,\n",
              "             '도': 31,\n",
              "             '더': 32,\n",
              "             '다': 33,\n",
              "             '쓰': 34,\n",
              "             '생각': 35,\n",
              "             '는데': 36,\n",
              "             '!': 37,\n",
              "             '신경': 38,\n",
              "             '저': 39,\n",
              "             '로': 40,\n",
              "             '았': 41,\n",
              "             'ㄴ': 42,\n",
              "             '하': 43,\n",
              "             '다시': 44,\n",
              "             '연출': 45,\n",
              "             '보': 46,\n",
              "             '에': 47,\n",
              "             '것': 48,\n",
              "             '는': 49,\n",
              "             '만족': 50,\n",
              "             '네요': 51,\n",
              "             '다는': 52,\n",
              "             '들': 53,\n",
              "             '습니다': 54,\n",
              "             '이': 55})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85oCOe0Xqcwk"
      },
      "source": [
        "### 3. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3uuFi52qjh6"
      },
      "source": [
        "#### 3.1 NaiveBayes Classifier 모델 클래스를 구현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsZlgjkBHAod"
      },
      "source": [
        "class NaiveBayesClassifier():\n",
        "    def __init__(self, word2index, k=0.1):\n",
        "        \"\"\"\n",
        "        (input) word2index: mapping a word to a pre-assigned index.\n",
        "        \"\"\"\n",
        "        self.k = k # for smoothing\n",
        "        self.word2index = word2index\n",
        "        self.priors = {} # Prior probability for each class, P(c)\n",
        "        self.likelihoods = {} # Likelihood for each token, P(d|c)\n",
        "\n",
        "    def _set_priors(self, labels):\n",
        "        \"\"\"\n",
        "        Set prior probability for each class, P(c).\n",
        "        Count the number of each class and calculate P(c) for each class.\n",
        "        \"\"\"\n",
        "\n",
        "        class_counts = defaultdict(int) # defalut int type dict\n",
        "        ############################ ANSWER HERE ################################\n",
        "        for label in tqdm(labels):\n",
        "          class_counts[label] += 1      # 0, 1의 갯수를 count\n",
        "\n",
        "        for label, count in class_counts.items():\n",
        "          self.priors[label] = class_counts[label] / len(labels) #P0 = 0.5, P1 = 0.5\n",
        "        #########################################################################\n",
        "\n",
        "    def _set_likelihoods(self, tokens, labels):\n",
        "        \"\"\"\n",
        "        Set likelihood for each token, P(d|c).\n",
        "        First, count the number of each class for each token.\n",
        "        Then, calculate P(d|c) for a given class and token.\n",
        "        \"\"\"\n",
        "        token_dists = {}\n",
        "        class_counts = defaultdict(int)\n",
        "\n",
        "        for i, label in enumerate(tqdm(labels)):\n",
        "            count = 0\n",
        "\n",
        "            ############################ ANSWER HERE ################################\n",
        "            for token in tokens[i]:\n",
        "              if token in word2index:\n",
        "                if token not in token_dists:\n",
        "                  token_dists[token] = {0:0, 1:0}\n",
        "                token_dists[token][label] += 1          # frequency가 아니라 긍정/부정수를 카운트 하는구나나\n",
        "            #########################################################################\n",
        "\n",
        "            count += 1\n",
        "            class_counts[label] += count               # likelihood의 분모로 쓰일 예정정\n",
        "\n",
        "        for token, dist in tqdm(token_dists.items()):\n",
        "            if token not in self.likelihoods:\n",
        "                self.likelihoods[token] = {\n",
        "                    0: (token_dists[token][0]+ self.k) / (class_counts[0] + len(self.word2index)* self.k),\n",
        "                    1: (token_dists[token][1]+ self.k) / (class_counts[1] + len(self.word2index)* self.k),\n",
        "                }\n",
        "\n",
        "    def train(self, input_tokens, labels):\n",
        "        \"\"\"\n",
        "        (input) input_tokens: list of tokenized train data.\n",
        "                labels: train labels for each sentence/document.\n",
        "        \"\"\"\n",
        "        self._set_priors(labels)\n",
        "        self._set_likelihoods(input_tokens, labels)\n",
        "\n",
        "    def inference(self, input_tokens):\n",
        "        \"\"\"\n",
        "        (input) input_tokens: list_of tokenized test data.\n",
        "        \"\"\"\n",
        "        log_prob_0 = 0.0\n",
        "        log_prob_1 = 0.0\n",
        "\n",
        "        for token in input_tokens:\n",
        "            if token in self.likelihoods:\n",
        "                log_prob_0 += math.log(self.likelihoods[token][0]) #chain-rule 공식에 log를 취함으로 덧셈으로 바뀜뀜\n",
        "                log_prob_1 += math.log(self.likelihoods[token][1])\n",
        "\n",
        "        log_prob_0 += math.log(self.priors[0])\n",
        "        log_prob_1 += math.log(self.priors[1])\n",
        "\n",
        "        if log_prob_0 >= log_prob_1:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzjVUyBOQEJk"
      },
      "source": [
        "#### 3.2 주어진 학습 데이터에 대해 문장 분류 모델을 학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt-iUEVRNsRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0b2713-2735-4186-aa3b-cc39fc7c371f"
      },
      "source": [
        "# 문장 분류 모델 선언 및 학습\n",
        "classifier = NaiveBayesClassifier(word2index)\n",
        "classifier.train(tokenized_data['train'], train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 109226.67it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 66788.28it/s]\n",
            "100%|██████████| 56/56 [00:00<00:00, 265402.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.likelihoods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL-T3QrGtmQW",
        "outputId": "6a76c98d-f092-41ff-9489-ab90f048d01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'정말': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '재미있': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '습니다': {0: 0.29245283018867924, 1: 0.3867924528301886},\n",
              " '.': {0: 0.5754716981132074, 1: 0.5754716981132074},\n",
              " '추천': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '하': {0: 0.29245283018867924, 1: 0.1981132075471698},\n",
              " 'ㅂ니다': {0: 0.009433962264150943, 1: 0.29245283018867924},\n",
              " '기대': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '었': {0: 0.5754716981132074, 1: 0.1981132075471698},\n",
              " '더': {0: 0.1981132075471698, 1: 0.009433962264150943},\n",
              " 'ㄴ': {0: 0.1981132075471698, 1: 0.009433962264150943},\n",
              " '것': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '보다': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '별': {0: 0.29245283018867924, 1: 0.009433962264150943},\n",
              " '로': {0: 0.29245283018867924, 1: 0.009433962264150943},\n",
              " '이': {0: 0.3867924528301886, 1: 0.1981132075471698},\n",
              " '네요': {0: 0.29245283018867924, 1: 0.009433962264150943},\n",
              " '지루': {0: 0.1981132075471698, 1: 0.009433962264150943},\n",
              " '어서': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '다시': {0: 0.10377358490566037, 1: 0.10377358490566037},\n",
              " '보': {0: 0.10377358490566037, 1: 0.10377358490566037},\n",
              " '고': {0: 0.10377358490566037, 1: 0.1981132075471698},\n",
              " '싶': {0: 0.10377358490566037, 1: 0.10377358490566037},\n",
              " '다는': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '생각': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '안': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '들': {0: 0.10377358490566037, 1: 0.10377358490566037},\n",
              " '완전': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '최고': {0: 0.009433962264150943, 1: 0.1981132075471698},\n",
              " '!': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '연기': {0: 0.10377358490566037, 1: 0.29245283018867924},\n",
              " '도': {0: 0.009433962264150943, 1: 0.5754716981132074},\n",
              " '연출': {0: 0.009433962264150943, 1: 0.29245283018867924},\n",
              " '다': {0: 0.009433962264150943, 1: 0.1981132075471698},\n",
              " '만족': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '스럽': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '가': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '좀': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '좋': {0: 0.10377358490566037, 1: 0.1981132075471698},\n",
              " '았': {0: 0.009433962264150943, 1: 0.1981132075471698},\n",
              " '배우': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '분': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '기념일': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '에': {0: 0.10377358490566037, 1: 0.10377358490566037},\n",
              " '방문': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '는데': {0: 0.009433962264150943, 1: 0.10377358490566037},\n",
              " '전반적': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '으로': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '저': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '는': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " 'CG': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '조금': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '신경': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '쓰': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '으면': {0: 0.10377358490566037, 1: 0.009433962264150943},\n",
              " '겠': {0: 0.10377358490566037, 1: 0.009433962264150943}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h79XWrsnQJtN"
      },
      "source": [
        "### 4. Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjk05W136d5o"
      },
      "source": [
        "각각의 Test 데이터에 대해 정답값을 추론하고 Accuracy를 구합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-fOScGNzH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9149ba8a-afd4-419b-ff4c-9b64c3b7270a"
      },
      "source": [
        "# Test 데이터 inference\n",
        "preds = []\n",
        "for test_tokens in tqdm(tokenized_data['test']):\n",
        "    pred = classifier.inference(test_tokens)\n",
        "    preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 27685.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrYMTKM10vYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685c4527-6dc7-4721-de9f-066ba1799502"
      },
      "source": [
        "# Accuracy 측정\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(test_labels, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}