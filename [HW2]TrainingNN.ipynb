{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/Study_Log/blob/DL/%5BHW2%5DTrainingNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW2] Training Neural Network**\n",
        "1. Prerequisite\n",
        "2. Activation\n",
        "3. Optimizer\n",
        "4. Regularization\n",
        "5. FC vs Conv\n",
        "6. Do it by yourself\n",
        "\n",
        "이번 실습에서는 지난 시간에 배웠던 MLP-layer의 component들을 하나씩 바꿔가며 activation, optimizer, regularization, convolution layer등의 중요성을 하나씩 익혀가는 시간을 갖도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3f6JjmmlC3"
      },
      "source": [
        "# 1. Prerequisite\n",
        "\n",
        "본격적인 실습을 진행하기 이전, 지난 [HW1.2 Logistic Regression vs MLP]에서 진행했던것과 동일하게 \\\\\n",
        "Mnist dataset에 대해서 DataLoader와 Trainer class를 생성해두겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crVJ36mMlaXP"
      },
      "source": [
        "\n",
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0"
      },
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32').values\n",
        "y = mnist.target.astype('int64').values\n",
        "X /= 255.0\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## Split Dataset\n",
        "\n",
        "학습과 평가를 위한 dataset으로 나눕니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnvqbdijWUQ"
      },
      "source": [
        "## Pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypqp7zA-xRlB"
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.from_numpy(np.array(y)).long()\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTr4OWatzmaU"
      },
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(train_dataset.X.shape)\n",
        "print(len(test_dataset))\n",
        "print(test_dataset.X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51PT-uPVzE8_"
      },
      "source": [
        "## DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2k3YVBoxRnF"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# shuffle the train data\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# do not shuffle the val & test data\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# dataset size // batch_size\n",
        "print(len(train_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN65oTBk1d4T"
      },
      "source": [
        "## Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqIwSltn9uY"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, model, optimizer, criterion, device):\n",
        "        \"\"\"\n",
        "        trainloader: train data's loader\n",
        "        testloader: test data's loader\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update your model\n",
        "        criterion: loss function\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "\n",
        "    def train(self, epoch = 1):\n",
        "        self.model.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "                # forward + backward + optimize\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs)\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        test_acc = correct / len(self.testloader.dataset)\n",
        "        print('test_acc: %.3f' %(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GnKJCB4T_Q"
      },
      "source": [
        "# 2. Activation Function\n",
        "\n",
        "이번 section에서는 가장 대표적으로 사용되는 sigmoid function과 relu function을 사용해보고 비교해보도록 하겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xfJBd9v9L_RgXGf8urNrYpb40zXU6gea)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhK8GHx0704"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- **activation: sigmoid or relu**\n",
        "- optimizer: sgd\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zPmZhpZlZkQ"
      },
      "source": [
        "## 2-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPfV0OTc4Xdr"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=32,\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqcfL4_qK6Q"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgD1bTOzqK-n"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxP2nzvVC_O"
      },
      "source": [
        "## 2-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRfskIWWQEf"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=32,\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKoXvlYryMK"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wcOPU_ryOg"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RyAkEQEr-OV"
      },
      "source": [
        "#### Q1. Activation Function에 따라 성능의 차이가 있나요? 있다면, 왜 차이가 발생했을까요?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D2tIM62sUW4"
      },
      "source": [
        "## 3-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29TauDy4ryQ0"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=(32,32),\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oS8LPa6ryVd"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCOr5-lryZy"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zPtZFsZtAVy"
      },
      "source": [
        "## 3-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xucFjeWLryd-"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=(32,32),\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQPzJum6t34S"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfVnHhN9t4vC"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICv5Wc_TuH3B"
      },
      "source": [
        "#### Q2. Activation function 별로 Layer 수를 늘리는 것이 성능이 어떻게 변하나요? 양상이 다르게 나타난다면 왜 그럴까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54oz80tfuH5M"
      },
      "source": [
        "\n",
        "#### Q3. Activation function이 존재하지 않는다면 어떤 일이 일어날까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrGO-uru01w"
      },
      "source": [
        "# 3. Optimization\n",
        "\n",
        "이번 section에서는 sgd, momentum, Adam등의 optimizer를 사용해보고 성능을 비교해보도록 하겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xfCTx8xj4zoaombrK2bSN9nv0Z3r95jp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jjuv9XW2Cij"
      },
      "source": [
        "- input: 784\n",
        "- hidden: (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- **optimizer: sgd or momentum or adam**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxhHMDjHxRV4"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=(32,32),\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlkMXZfKxpRg"
      },
      "source": [
        "## 3-layer Network + ReLU + SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCDbH1Bbxify"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lchz9vtUxkiD"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksQiJFqxls_"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1nhBnqWxw4a"
      },
      "source": [
        "## 3-layer Network + ReLU + Momentum\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idG8_h_QxmQi"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDNAysVqxxOk"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0U2s0hux_n6"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZobOWhPxytT"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7xVOWgZxzoS"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4pzcKPyFBi"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgAEpCJ_yHAi"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCeNbNhIyyR6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLVGSb7yyWW"
      },
      "source": [
        "#### Q4. Optimizer 별로 수렴 속도가 어떻게 다른가요?\n",
        "##### Q4.1 수렴 속도가 다르다면 sgd와 momentum의 차이는 왜 발생할까요?\n",
        "##### Q4.2 수렴 속도가 다르다면 momentum과 Adam의 차이는 왜 발생할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNP78kE2zbPQ"
      },
      "source": [
        "## 4. Regularization\n",
        "\n",
        "이번 section에서는 image data에서 주로 사용되는 batch-normalization을 어떻게 사용하는지를 확인해보겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xZSWZiSxuGZAsonghidhTSfUEYiuxRtN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1YretVf2eRy"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- optimizer: adam\n",
        "- **regularizer: batch_norm**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmvn2oNj0Spe"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam + batch_norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FBt1qcYzrph"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 hidden_dim=(32,32),\n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VSAzG4uz_4i"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYfHC9x0BKy"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpSN6uu0CZy"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qDotwtf3m-Q"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WSYxs4F0Kbt"
      },
      "source": [
        "#### Q5. Batch-normalization을 사용하기 전 후로 성능이 어떻게 변화했나요? 왜 이러한 변화가 일어났을까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6xu4cQl0fOy"
      },
      "source": [
        "# 5. Fully-Connected Layer vs Convolution Layer\n",
        "\n",
        "지금까지 model의 다양한 node를 바꿔가며 mnist의 성능 변화를 확인해보는 실습을 진행해 보았습니다. \\\\\n",
        "비록, fully-connected network가 mnist 데이터에서 높은 성능을 내는데는 문제가 없었지만, 모든 layer를 fully-connected layer로 만드는 것은 엄청난 파라미터와 연산량을 필요로 하기 때문에 더욱 큰 고화질의 이미지 데이터를 처리하는데는 적합하지 않습니다. \\\\\n",
        "\n",
        "따라서, 이번 section에서는 이미지 데이터 처리에 주로 사용되는 convolution layer를 사용해보고 파라미터 수와 성능이 어떻게 변화하는지 확인해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBH4WROS2-H4"
      },
      "source": [
        "## Convolution Operation\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xdjTf4ab0P8qfu_TaLJ4TZzt5sk3twS6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u86dyWA98qQ_"
      },
      "source": [
        "### Q6. Input이 (H, W, C) 일 때, stride S의 2개의 (F * F) convolutional filter를 적용하면 output이 어떻게 되나요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tfEDx7429cL"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 output_dim=10):\n",
        "        super(Conv, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.fc = nn.Linear(3*3*8, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # should reshape data into image\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.reshape(-1, 3*3*8)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2QbRqEz-FzB"
      },
      "source": [
        "model = Conv()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTRB0_15-eYy"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuFiCnDa-fpC"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRVwFbhU-8TZ"
      },
      "source": [
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayzu25pm_KNH"
      },
      "source": [
        "##### Q7. covolution operation은 image데이터를 다루는데 있어서 fully-connected layer에 비해 어떤 점에서 효과적일까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdCwjzXX_-jU"
      },
      "source": [
        "## 6. Do It By Yourself\n",
        "\n",
        "위에서 했던 실습들과 수업에 배웠던 다양한 network component들을 참조해서 20,000개 이하의 파라미터로 98%의 accuracy를 달성해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOqAaJkGAAuC"
      },
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 output_dim=10):\n",
        "      super(CustomModel, self).__init__()\n",
        "      pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B-6gww_Af0E"
      },
      "source": [
        "model = CustomModel()\n",
        "if count_parameters(model) > 20000:\n",
        "  raise AssertionError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcA3XbRUAaUh"
      },
      "source": [
        "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBKdQTyAd24"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0URQgBu_AfJB"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fp_V8lHJH2lR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}