{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/Study_Log/blob/DL/%5BDL_HW1_1%5DPytorchTutorial_%EC%9D%B4%EC%9E%AC%EC%98%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW1.1] PyTorch Tutorial**\n",
        "1. Install packages\n",
        "2. Tensor\n",
        "3. AutoGrad\n",
        "\n",
        "딥러닝 실습은, 수업시간에 배웠던 개념들을 직접 코드로 옮겨보며 이를 폭넓게 이해하는 데에 초점을 맞추고 있습니다. 실습에서 사용한 예시 외에도, 다양한 architecture를 직접 구성해보며 각 node와 function의 역할을 명확히 이해해보시길 바랍니다.\n",
        "\n",
        "이번 실습에서는 딥러닝 모델을 만들때 사용하는 PyTorch library에 대한 기본 개념들을 익혀보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iquuOQj1g9"
      },
      "source": [
        "# 1. Import packages\n",
        "\n",
        "> 필요한 package를 설치하고 import합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6145d7-a02e-4d90-e8cc-c4f8c3ce9e16"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "# 2. Tensor operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQqLw-Dl_Zw"
      },
      "source": [
        "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n",
        "\n",
        "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XqtZa8sXsw"
      },
      "source": [
        "##텐서 초기화하기\n",
        "\n",
        "데이터로부터 직접 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbfac7f-09ff-4dda-dd2c-b3674026a4d0"
      },
      "source": [
        "data = [[1, 2],[3, 4]] # row 방향 삽입\n",
        "x = torch.tensor(data) # list to tensor\n",
        "x[1,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZx51U6fUXSc"
      },
      "source": [
        "Numpy array로부터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5m4qus2UnoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862b7b18-8088-425a-deb4-e63e4ac4c743"
      },
      "source": [
        "np_array = np.array(data) # np_array = np.array(data)\n",
        "x = torch.from_numpy(np_array) # torch.from_numpy(np_array)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfwipaTYEFI"
      },
      "source": [
        "Tensor에서 Numpy array로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkEJ9mBMCOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08048808-23f4-4206-c3af-3e39ab88e84c"
      },
      "source": [
        "x.numpy() # tensor to array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ-A5rxYOSx"
      },
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJRGOaEyyc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e068ab-fc98-4309-be9b-2de62288c5b6"
      },
      "source": [
        "x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.4792, 0.3572],\n",
            "        [0.9105, 0.1618]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1E5bEPHZskg"
      },
      "source": [
        "주어진 shape으로 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1OASeazKtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e70de89-066e-47b3-b1b3-35250b6d16b3"
      },
      "source": [
        "shape = (3,4)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8819, 0.0433, 0.8979, 0.0180],\n",
            "        [0.0304, 0.2951, 0.2048, 0.4184],\n",
            "        [0.6695, 0.1928, 0.6774, 0.0014]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## 텐서의 속성\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7926ef5-b199-4d94-ea8f-da4406a3c8da"
      },
      "source": [
        "tensor = torch.rand(3,4) # 3 by 4 size matrix with random number\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7LymV5aYEA"
      },
      "source": [
        "아래와 같이 cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvYqt3ZaOXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df750f8-128b-468e-e661-dae4057af735"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01vssH7n24cq"
      },
      "source": [
        "## 텐서 연산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqON2YtYczmS"
      },
      "source": [
        "Numpy식의 인덱싱과 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv_w4LhjTDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee809a52-29a0-4940-a652-608dfbb782dd"
      },
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "tensor[:,1] = 0 # all row, col 1을 0으로\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[tensor, tensor, tensor]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLzzRnD5cSTp",
        "outputId": "b54ae010-1d5b-478f-d651-40d6a87ed29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.]]), tensor([[1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.]]), tensor([[1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.],\n",
              "         [1., 0., 1., 1.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0J9p1WkpHO"
      },
      "source": [
        "텐서 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68HmhqlknkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8349d61-f41a-467b-d2b1-b06e1e056cbe"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0) # 위아래\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxrFYAjbQuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1db135-5eb3-4474-ea74-944d9b451987"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1) # 양 옆\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThLzN1ONbV-p"
      },
      "source": [
        "텐서 곱하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMMXj8ejXVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402d523b-65a0-4858-e3fa-41523b071098"
      },
      "source": [
        "# 요소별 곱(element-wise product)을 계산합니다\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "# 다른 문법:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9752P1u90enu"
      },
      "source": [
        "텐서간 matrix multiplication 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhOPv757T4NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c7cc84-a396-4487-8922-660a07af5fde"
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_i0POOIf0M"
      },
      "source": [
        "# 3. AUTOGRAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQLTW4vcRJK"
      },
      "source": [
        "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다.\n",
        "이는 모든 node에 대한 미분 값을 자동으로 계산해주게 됩니다.\n",
        "\n",
        "입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3w8_NGdCL1"
      },
      "source": [
        "## 입력 및 파라미터 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zAKX7zLl7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708f3e3e-0975-4b24-bc65-d9646586f1dc"
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "print(y)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0.])\n",
            "tensor([[-0.4406,  2.5770,  1.4182],\n",
            "        [ 0.1078, -0.9587,  1.2926],\n",
            "        [ 1.3858, -0.1644,  1.4910],\n",
            "        [-0.9328, -0.5681,  1.6472],\n",
            "        [ 0.3858, -1.1217,  0.6739]], requires_grad=True)\n",
            "tensor([-1.1090, -0.3654, -0.1001], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfSzTTVUeb06"
      },
      "source": [
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09v6hrSIecG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9345ec8-08d4-45b6-c623-d989558d61df"
      },
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6029, -0.6012,  6.4228], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R19jHY9Pemt"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "PyTorch에서는 node를 크게 2가지의 방법의 api를 활용해서 사용합니다.\n",
        "\n",
        "1. [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "2. [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "\n",
        "torch.nn은 사전에 node를 초기화 시켜놓고, 해당 node에 텐서를 통과시켜 값을 받는 형태인 반면, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n",
        "\n",
        "코딩 스타일에 맞춰 원하시는 api를 선택하셔서 사용하시면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQe1Nw8QLMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e322f8-f286-49d7-f59c-93a487a2d80d"
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss() # torch.nn은 node를 초기화 시켜놓고\n",
        "loss = loss_fn(z, y) # 텐서를 통과시켜 값을 받음\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4327, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gihsaH3ULCRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69e9252-090d-48b8-c0f6-e6790807ce88"
      },
      "source": [
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y) # torch.nn.functional은 초기화 없이 바로 함수처럼 사용함\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4327, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCsd5yep3-sj"
      },
      "source": [
        "## Backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfNejCDye61c"
      },
      "source": [
        "모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다.\n",
        "이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptZdnLSu5vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a839aaea-3c98-4d45-9049-2f719731a69c"
      },
      "source": [
        "loss.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[0.1179, 0.1180, 0.3328],\n",
            "        [0.1179, 0.1180, 0.3328],\n",
            "        [0.1179, 0.1180, 0.3328],\n",
            "        [0.1179, 0.1180, 0.3328],\n",
            "        [0.1179, 0.1180, 0.3328]])\n",
            "tensor([0.1179, 0.1180, 0.3328])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7073, 0.7081, 1.9968])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFE4lc-lfYtf"
      },
      "source": [
        "기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiqxruWT_so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acd6cf3-da34-4d43-9f97-dd9c4ad8b109"
      },
      "source": [
        "z = torch.matmul(x, w)+b #선형결합\n",
        "print(z.requires_grad) # tensor에 requires_grad=True 옵션을 사용하면 미분 연산을 위한 값들이 저장됨.\n",
        "\n",
        "with torch.no_grad(): # 메모리 관리차원에서 추적 정지\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NqQRDaKqU6"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. https://tutorials.pytorch.kr/index.html"
      ]
    }
  ]
}