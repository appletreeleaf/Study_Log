{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41dbfc2b71d94fb4ad9bea2ac155f338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65b3557f089d4d178810fc793847a5f5",
              "IPY_MODEL_59d09be3fb0e4630b05cf79af6c1669f",
              "IPY_MODEL_9fa2da72f9bf4653b1077ccb0cc32674"
            ],
            "layout": "IPY_MODEL_3bf83eaae872444880c48f127be300e8"
          }
        },
        "65b3557f089d4d178810fc793847a5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0291d5f8937d4932a78bdfdc99546239",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_252bf014428b45d395b9824500079c56",
            "value": "Downloading (‚Ä¶)solve/main/vocab.txt: 100%"
          }
        },
        "59d09be3fb0e4630b05cf79af6c1669f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c518d96978924da49e4d49b696b79f95",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25e5fdf8181d40c9bdd56c63cd02fd09",
            "value": 213450
          }
        },
        "9fa2da72f9bf4653b1077ccb0cc32674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1fe30f3d0b4ad19625729c95dedc26",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cb10e3ff6aa749988cfb679d5ed894b1",
            "value": " 213k/213k [00:00&lt;00:00, 242kB/s]"
          }
        },
        "3bf83eaae872444880c48f127be300e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0291d5f8937d4932a78bdfdc99546239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252bf014428b45d395b9824500079c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c518d96978924da49e4d49b696b79f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e5fdf8181d40c9bdd56c63cd02fd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f1fe30f3d0b4ad19625729c95dedc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb10e3ff6aa749988cfb679d5ed894b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33bd2f84bce74cd3a5951f90561da57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc9f5b44f1324e82b0056986b5ed5835",
              "IPY_MODEL_eafda655879143eca81f7ec33fb32dca",
              "IPY_MODEL_77c7f01fc242444282cfeae47d3f9dd9"
            ],
            "layout": "IPY_MODEL_a15333b0fa75433ea623c4d9d9caf7be"
          }
        },
        "fc9f5b44f1324e82b0056986b5ed5835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceaabbe9ba1e40649c7702854cb2593d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ca7e353288b348c582324be4d4a2d28a",
            "value": "Downloading (‚Ä¶)okenizer_config.json: 100%"
          }
        },
        "eafda655879143eca81f7ec33fb32dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1008334ad74afdab0bb9fe9f889632",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b93d8e23b45343ddb07d3dfb7999d0ee",
            "value": 29
          }
        },
        "77c7f01fc242444282cfeae47d3f9dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0137c3932e9740708b0b54d0f877b3e5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8e433df75af0422da616d79e8443244d",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.12kB/s]"
          }
        },
        "a15333b0fa75433ea623c4d9d9caf7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceaabbe9ba1e40649c7702854cb2593d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7e353288b348c582324be4d4a2d28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1008334ad74afdab0bb9fe9f889632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b93d8e23b45343ddb07d3dfb7999d0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0137c3932e9740708b0b54d0f877b3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e433df75af0422da616d79e8443244d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbc19d31ca3b4ce89c4d057ed4f96baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4439fcb8b23844aaae62b2c1071db439",
              "IPY_MODEL_bfdd662c123d4c29b3af9b75d351ee53",
              "IPY_MODEL_2c3bb738c3ee434cb437d30288a77d5f"
            ],
            "layout": "IPY_MODEL_144e5faf99924bbcb435941270fb86db"
          }
        },
        "4439fcb8b23844aaae62b2c1071db439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b38e5b867f401cb75732c0b5007847",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a11ef5e6e0c94546b6d6a6296d0aea34",
            "value": "Downloading (‚Ä¶)lve/main/config.json: 100%"
          }
        },
        "bfdd662c123d4c29b3af9b75d351ee53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c854eb1a9b4e0d9f47ae2a55a47ef5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49a38656f9874682a11534ef025ac85e",
            "value": 570
          }
        },
        "2c3bb738c3ee434cb437d30288a77d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2258afa59c9e4aa28d52e8fc0ff2cd1a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c02adae90d324626b62fcc3e9b00588d",
            "value": " 570/570 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "144e5faf99924bbcb435941270fb86db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b38e5b867f401cb75732c0b5007847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11ef5e6e0c94546b6d6a6296d0aea34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c854eb1a9b4e0d9f47ae2a55a47ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a38656f9874682a11534ef025ac85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2258afa59c9e4aa28d52e8fc0ff2cd1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02adae90d324626b62fcc3e9b00588d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/Study_Log/blob/NLP/%5BHW30%5D_Sub_word_Tokenization_%EC%9D%B4%EC%9E%AC%EC%98%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOnz8OxdbN3y"
      },
      "source": [
        "# Tokenization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZb_LOZr7XF_"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "\n",
        "*   Îç∞Ïù¥ÌÑ∞(train, dev, test)Í∞Ä Ï†ÄÏû•Îêú ÎìúÎùºÏù¥Î∏åÎ•º ÎßàÏö¥Ìä∏ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨Ïò¨ Ïàò ÏûàÎäî Í≤ΩÎ°úÎ•º Ï§ÄÎπÑÌï©ÎãàÎã§.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkCrAHWVmUck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86468c90-0e61-4be2-814a-c0c3bb158ef0"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌòÑÏû¨ ÌååÏùº Í≤ΩÎ°úÏóê ÎßûÍ≤å ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "K2S1sTM_cE7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9yYsxMfyZsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3f2076-d5d0-4c98-c44e-a9c0f8a25ea2"
      },
      "source": [
        "# ÌòÑÏû¨ Í≤ΩÎ°ú ÌôïÏù∏\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1pje9LlFzRHy_EpwXMasZRKJxfWtlP9xW/data/wikitext-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceOZZ8UOU4or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c27fadc-a363-489b-a4ea-73980894e908"
      },
      "source": [
        "# ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNON1TAbj2i"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "\n",
        "* Î≥∏ Í≥ºÏ†úÏùò Î™©Ï†ÅÏùÄ Subword tokenizationÏùò ÌïÑÏöîÏÑ±ÏùÑ ÏßÅÏ†ë ÎäêÍª¥Î≥¥Îäî Í≤ÉÏûÖÎãàÎã§.\n",
        "* Subword tokenization Í∏∞Î∞ò language modelÏùÑ Íµ¨ÌòÑÌïòÎ©¥ÏÑú Ïù¥Ï†Ñ Í≥ºÏ†úÏùò Word-level language modelÍ≥º ÎπÑÍµêÌï¥Î≥¥Îäî ÏãúÍ∞ÑÏùÑ Í∞ñÍ≤†ÏäµÎãàÎã§. Ï∂îÍ∞ÄÏ†ÅÏúºÎ°ú RNNÏùÑ LSTMÏúºÎ°ú Î≥ÄÍ≤ΩÌñàÏùÑ ÎïåÏùò ÏÑ±Îä• Ï∞®Ïù¥Ïóê ÎåÄÌï¥ ÏÇ¥Ìé¥Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "*   Subword-level language modelÏùÑ Íµ¨ÌòÑÌïòÍ≥†, Ï£ºÏñ¥ÏßÑ Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÍ≥µÌïòÏó¨ Î™®Îç∏ÏùÑ ÌïôÏäµÌïú ÌõÑ ÌïôÏäµÎêú Ïñ∏Ïñ¥ Î™®Îç∏ÏùÑ Ïù¥Ïö©Ìï¥ Î¨∏Ïû•ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzSMF9RJyzg"
      },
      "source": [
        "\n",
        "```\n",
        "üí° SubwordÎäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n",
        "\n",
        "SubwordÎäî ÌïòÎÇòÏùò Îã®Ïñ¥Î•º Ïó¨Îü¨Í∞úÏùò Îã®ÏúÑÎ°ú Î∂ÑÎ¶¨ÌñàÏùÑ Îïå ÌïòÎÇòÏùò Îã®ÏúÑÎ•º ÎÇòÌÉÄÎÉÖÎãàÎã§. \"subword\"Î•º subword Îã®ÏúÑÎ°ú ÎÇòÌÉÄÎÇ∏ ÌïòÎÇòÏùò ÏòàÏãúÎäî Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
        "\n",
        "\"sub\" + \"word\"\n",
        "\n",
        "subÎùºÎäî Ï†ëÎëêÏÇ¨ÏôÄ wordÎùºÍ≥† ÌïòÎäî Ïñ¥Í∑ºÏúºÎ°ú ÎÇòÎàÑÏñ¥ \"subword\"ÎùºÍ≥† ÌïòÎäî wordÎ•º 2Í∞úÏùò subwordÎ°ú ÎÇòÌÉÄÎÉàÏäµÎãàÎã§.\n",
        "\n",
        "Ïù¥Ïô∏ÏóêÎèÑ Îã§ÏñëÌïú ÌòïÌÉúÏùò subwordÎ°ú ÎÇòÌÉÄÎÇº Ïàò ÏûàÏäµÎãàÎã§. (e.g., \"su\" + \"bword\", \"s\" + \"ubword\", \"subwor\" + \"d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgY-yRfVJON"
      },
      "source": [
        "```\n",
        "üí° tokenizationÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n",
        "\n",
        "tokenizationÏùÄ Ï£ºÏñ¥ÏßÑ ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨ Î™®Îç∏Ïù¥ Ïù∏ÏãùÌï† Ïàò ÏûàÎäî Îã®ÏúÑÎ°ú Î≥ÄÌôòÌï¥Ï£ºÎäî Î∞©Î≤ïÏûÖÎãàÎã§.\n",
        "\n",
        "üí° word tokenizationÏùÄÏöî?\n",
        "\n",
        "word tokenizationÏùò Í≤ΩÏö∞ \"Îã®Ïñ¥\"Í∞Ä ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨ Î™®Îç∏Ïù¥ Ïù∏ÏãùÌïòÎäî Îã®ÏúÑÍ∞Ä Îê©ÎãàÎã§.\n",
        "\"I have a meal\"Ïù¥ÎùºÍ≥† ÌïòÎäî Î¨∏Ïû•ÏùÑ Í∞ÄÏßÄÍ≥† word tokenizationÏùÑ ÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
        "\n",
        "- ['I', 'have', 'a', 'meal']\n",
        "\n",
        "ÏòÅÏñ¥Ïùò Í≤ΩÏö∞ ÎåÄÎ∂ÄÎ∂Ñ spaceÎ•º Í∏∞Ï§ÄÏúºÎ°ú Îã®Ïñ¥Í∞Ä Ï†ïÏùòÎêòÍ∏∞ ÎïåÎ¨∏Ïóê .split()ÏùÑ Ïù¥Ïö©Ìï¥ ÏâΩÍ≤å word tokenizationÏùÑ Íµ¨ÌòÑÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "ÏòÅÏñ¥ÏóêÏÑú word tokenizationÏùÄ space tokenizationÏù¥ÎùºÍ≥†ÎèÑ Ìï† Ïàò ÏûàÍ≥†,\n",
        "subword tokenization Ïù¥Ï†ÑÏóê ÏàòÌñâÎêòÎäî pre-tokenization Î∞©Î≤ïÏúºÎ°úÎèÑ ÎßéÏù¥ ÏÇ¨Ïö©Îê©ÎãàÎã§.\n",
        "\n",
        "\"ÎÇòÎäî Î∞•ÏùÑ Î®πÎäîÎã§\"ÎùºÎäî Î¨∏Ïû•ÏùÑ word tokenizationÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
        "- ['ÎÇò', 'Îäî', 'Î∞•', 'ÏùÑ', 'Î®πÎäîÎã§']\n",
        "\n",
        "ÌïúÍµ≠Ïñ¥ÏóêÏÑú \"Îã®Ïñ¥\"Îäî Í≥µÎ∞±(space)ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÏùòÎêòÏßÄ ÏïäÏäµÎãàÎã§. Ïù¥Îäî ÌïúÍµ≠Ïñ¥Í∞Ä Í∞ñÍ≥† ÏûàÎäî \"ÍµêÏ∞©Ïñ¥\"Î°úÏÑúÏùò ÌäπÏßï ÎïåÎ¨∏ÏûÖÎãàÎã§.\n",
        "Ï≤¥Ïñ∏ Îí§Ïóê Ï°∞ÏÇ¨Í∞Ä Î∂ôÎäî Í≤ÉÏù¥ ÎåÄÌëúÏ†ÅÏù∏ ÌäπÏßïÏù¥Î©∞ ÏùòÎØ∏ Îã®ÏúÑÍ∞Ä Íµ¨Î∂ÑÎêòÍ≥† ÏûêÎ¶ΩÏÑ±Ïù¥ ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê Ï°∞ÏÇ¨Îäî \"Îã®Ïñ¥\"ÏûÖÎãàÎã§.\n",
        "\n",
        "ÌïúÍµ≠Ïñ¥ÏóêÏÑúÎäî pre-tokenization Î∞©Î≤ïÏúºÎ°ú space tokenizationÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÍ≥† ÌòïÌÉúÏÜå Î∂ÑÏÑùÍ∏∞Î•º ÌôúÏö©ÌïòÍ≥† ÏûàÏäµÎãàÎã§.\n",
        "```\n",
        "\n",
        "(Ï∞∏Í≥†1: [Íµ≠Î¶Ω Íµ≠Ïñ¥Ïõê: \"Ï°∞ÏÇ¨Îäî Îã®Ïñ¥Ïù¥Îã§\"](https://www.korean.go.kr/front/onlineQna/onlineQnaView.do?mn_id=216&qna_seq=26915#:~:text='%EC%A1%B0%EC%82%AC'%EB%8A%94%20%EC%99%84%EC%A0%84%ED%95%9C%20%EC%9E%90%EB%A6%BD%EC%84%B1%EC%9D%80,%ED%95%98%EC%97%AC%20%EB%8B%A8%EC%96%B4%EB%A1%9C%20%EC%B2%98%EB%A6%AC%ED%95%A9%EB%8B%88%EB%8B%A4.) )\n",
        "\n",
        "(Ï∞∏Í≥†2: [Huggingface: Pre-tokenization](https://huggingface.co/docs/tokenizers/python/latest/pipeline.html#pre-tokenization))\n",
        "\n",
        "(Ï∞∏Í≥†3: [Konlpy: ÌòïÌÉúÏÜå Î∂ÑÏÑùÍ∏∞](https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVQgjQJdAbWh"
      },
      "source": [
        "```\n",
        "üí° Í∑∏Îüº Subword tokenizationÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n",
        "\n",
        "Subword tokenizaitonÏùÄ Îßê Í∑∏ÎåÄÎ°ú subword Îã®ÏúÑÎ°ú tokenizationÏùÑ ÌïúÎã§Îäî ÎúªÏûÖÎãàÎã§.\n",
        "Î∞©Í∏à Ï†Ñ word tokenizationÏùÑ ÏàòÌñâÌñàÎçò Î¨∏Ïû•ÏùÑ Ïù¥Ïö©Ìï¥ subword tokenizationÏùÑ ÏàòÌñâÌïú ÏòàÏãúÎ•º Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "\n",
        "Subword tokenizationÏùÑ Ï†ÅÏö©ÌñàÏùÑ ÎïåÎäî Îã§ÏùåÍ≥º Í∞ôÏù¥ tokenizationÏù¥ Îê† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "Example 1\n",
        "\n",
        "\"I have a meal\" -> ['I', 'hav', 'e', 'a', 'me', 'al']\n",
        "\"ÎÇòÎäî Î∞•ÏùÑ Î®πÎäîÎã§\" -> ['ÎÇò', 'Îäî', 'Î∞•', 'ÏùÑ', 'Î®πÎäî', 'Îã§']\n",
        "\n",
        "word Îã®ÏúÑÍ∞Ä ÏïÑÎãàÎùº Í∑∏Î≥¥Îã§ Îçî ÏûòÍ≤å Ï™ºÍ∞† subword Îã®ÏúÑÎ°ú Î¨∏Ïû•ÏùÑ tokenizationÌï©ÎãàÎã§.\n",
        "\n",
        "ÏúÑÏóêÏÑú ÎßêÏîÄÎìúÎ¶∞ Í≤ÉÍ≥º Í∞ôÏù¥ Ïó¨Îü¨Í∞ÄÏßÄ Í≤ΩÏö∞Ïùò ÏàòÍ∞Ä Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
        "\n",
        "Example 2\n",
        "\n",
        "\"I have a meal\" -> ['I', 'ha', 've', 'a', 'mea', 'l']\n",
        "\"ÎÇòÎäî Î∞•ÏùÑ Î®πÎäîÎã§\" -> ['ÎÇò', 'Îäî', 'Î∞•', 'ÏùÑ', 'Î®π', 'ÎäîÎã§']\n",
        "\n",
        "Í∑∏Î†áÏßÄÎßå Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Í≥µÎ∞±ÏùÑ ÎÑòÏñ¥ÏÑ† subwordÎ•º Íµ¨ÏÑ±ÌïòÏßÑ ÏïäÏäµÎãàÎã§.\n",
        "Ï¶â, Ïù¥ÎØ∏ ÎùÑÏñ¥Ïì∞Í∏∞Í∞Ä ÎêòÏñ¥ÏûàÎäî ÏÉÅÌÉúÎ•º Íµ≥Ïù¥ Îã§Ïãú Ìï©Ï≥ê Íµ¨ÏÑ±ÌïòÏßÑ ÏïäÏäµÎãàÎã§.\n",
        "ÏòàÎ•º Îì§Ïñ¥ Îã§ÏùåÍ≥º Í∞ôÏù¥ tokenizaitonÏùÑ ÏàòÌñâÌïòÏßÑ ÏïäÏäµÎãàÎã§.\n",
        "\n",
        "Example 3\n",
        "\n",
        "\"I have a meal\" -> ['Iha', 've', 'am', 'ea', 'l']\n",
        "\"ÎÇòÎäî Î∞•ÏùÑ Î®πÎäîÎã§\" -> ['ÎÇòÎäîÎ∞•', 'ÏùÑÎ®π', 'ÎäîÎã§']\n",
        "```\n",
        "\n",
        "(Ï∞∏Í≥†4: [Huggingface: subword-tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPRNaFhMEK67"
      },
      "source": [
        "```\n",
        "üí° Subword tokenizationÏùÄ Ïôú ÌïÑÏöîÌïúÍ∞ÄÏöî?\n",
        "\n",
        "word tokenization ÏΩîÎìúÎ•º Î∂àÎü¨ÏôÄ Í∑∏ ÌïÑÏöîÏÑ±ÏùÑ ÏÉùÍ∞ÅÌï¥ Î¥ÖÏãúÎã§.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DESsQzhwGVST"
      },
      "source": [
        "import os\n",
        "from io import open\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWd09aUBGWa9"
      },
      "source": [
        "class Dictionary(object):   # vocab\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<unk>': 0} # dict\n",
        "        self.idx2word = ['<unk>']    # list\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:     # idx2wordÏóê Ìï¥Îãπ Îã®Ïñ¥Í∞Ä ÏóÜÎã§Î©¥\n",
        "            self.idx2word.append(word)    # Ìï¥Îãπ wordÎ•º Ï∂îÍ∞ÄÌïòÍ≥†\n",
        "            self.word2idx[word] = len(self.idx2word) - 1    #word2idxÏóê Ìï¥Îãπ Îã®Ïñ¥Ïóê ÎåÄÏùëÎêòÎäî idxÍ∞íÏùÑ ÏóÖÎç∞Ïù¥Ìä∏Ìä∏\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)         # vocabÏùò Í∏∏Ïù¥Î•º return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQIyGQlfd9Os"
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)   # pathÍ∞Ä Ïú†Ìö®ÌïòÎã§Î©¥ Return True.\n",
        "        # Add words to the dictionary\n",
        "        with open(os.path.join(path, 'train.txt'), 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>'] # ex) [i, study, math, <eos>]\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word) # dictÏóê tokenÏùÑ Ï∂îÍ∞ÄÌï¥Ï§å\n",
        "\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = [] # Ï†ÑÏ≤¥ textÎ•º Îã¥ÏùÑ Í≥µÍ∞Ñ\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = [] # Í∞Å Î¨∏Ïû•Îì§ÏùÑ indexÍ∞íÏúºÎ°ú Î≥ÄÍ≤ΩÌïú Í∞íÏù¥ Îã¥ÍπÄÍπÄ\n",
        "                for word in words:\n",
        "                    try:\n",
        "                        ids.append(self.dictionary.word2idx[word]) # wordÏóê ÎåÄÏùëÎêòÎäî indexÍ∞íÎì§Ïù¥ Îã¥Í≤®Ïöî\n",
        "                    except: # ERROR Î∞úÏÉù = vocabÏóê ÏóÜÎäî Îã®Ïñ¥ Î∞úÏÉùÏÉù\n",
        "                        print(word)\n",
        "                        ids.append(0) # <unk>ÏúºÎ°ú ÎåÄÏ≤¥Ï≤¥\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a55D0z53eLzB"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange) # -0.1~0.1 Î≤îÏúÑÏùò Ïú†ÎãàÌèº ÎÇúÏàò\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input)) # drop?\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1, self.ntoken)\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDQTvkdJdZOk"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import easydict\n",
        "args = easydict.EasyDict({\n",
        "    \"data\"    : './data/wikitext-2',    # location of the data corpus\n",
        "    \"model\"   : 'RNN_TANH',             # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU)\n",
        "    \"emsize\"  : 200,                    # size of word embeddings\n",
        "    \"nhid\"    : 512,                    # number of hidden units per layer (ÌûàÎì† Î†àÏù¥Ïñ¥ Ìïú Ï∏µÏùò ÎÖ∏Îìú Ïàò)\n",
        "    \"nlayers\" : 2,                      # number of layers\n",
        "    \"lr\"      : 20,                     # initial learning rate\n",
        "    \"clip\"    : 0.25,                   # gradient clipping\n",
        "    \"epochs\"  : 6,                      # upper epoch limit\n",
        "    \"batch_size\": 20,                   # batch size\n",
        "    \"bptt\"    : 35,                     # sequence length\n",
        "    \"dropout\" : 0.2,                    # dropout applied to layers (0 = no dropout)\n",
        "    \"seed\"    : 1111,                   # random seed\n",
        "    \"cuda\"    : True,                   # use CUDA\n",
        "    \"log_interval\": 200,                # report interval\n",
        "    \"save\"    : 'model.pt',             # path to save the final model\n",
        "    \"dry_run\" : True,                   # verify the code and the model\n",
        "\n",
        "})\n",
        "\n",
        "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnsZkQqUHb6Z"
      },
      "source": [
        "```\n",
        "train.txtÏùò Î¨∏Ïû•Îì§ÏùÑ word tokenization Ìï¥Î≥¥Í≥† Îã®Ïñ¥Îì§Ïùò Í∞úÏàòÎ•º ÏÑ∏Ïñ¥Î≥¥Í≤†ÏäµÎãàÎã§\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aSB9Hk4HjyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5284a152-f896-4dc5-a632-6a79aced76ab"
      },
      "source": [
        "corpus = Corpus('./data/wikitext-2')\n",
        "ntokens = len(corpus.dictionary)\n",
        "print(ntokens)  # vocab(ÏÇ¨Ï†Ñ)Ïùò size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkvRpEcKEvd"
      },
      "source": [
        "```\n",
        "Ïù¥Ï†Ñ Í≥ºÏ†úÏóê ÏÇ¨Ïö©Îêú embedding dimensionÏùò ÌÅ¨Í∏∞Îäî 200Ïù¥ÎØÄÎ°ú word embeddingÏóê ÏÇ¨Ïö©Îêú parameterÏùò ÏàòÎäî 33278 x 200 (6,655,600Í∞ú)ÏûÖÎãàÎã§.\n",
        "-> parameterÎùºÎäî ÌëúÌòÑÏùòÏùò Ïù¥Ïú†Îäî Ïö∞Î¶¨Í∞Ä ÏßÄÏ†ïÌïú embedding dimÏù¥ 200Ïù¥ÎùºÎ©¥ Í∞ÅÍ∞Å wordÎßàÎã§ 200 dimensionÏùò Î≤°ÌÑ∞Î°ú ÌëúÌòÑÎêúÎã§. Ï≤òÏùåÏóî ÎûúÎç§Ìïú Í∞íÏúºÎ°ú Ï¥àÍ∏∞Ìôî ÎêòÍ≥†, ÌõÑÏóê ÌïôÏäµÏùÑ ÌïòÎ©¥ÏÑú embedding vectorÎì§Ïù¥ update ÎêòÍ∏∞ ÎñÑÎ¨∏Ïóê  \n",
        "Í∑∏Î†áÎã§Î©¥, RNN Î™®Îç∏Ïóê ÏÇ¨Ïö©ÎêòÎäî weightÏùò parameter Í∞úÏàòÎäî Î™áÍ∞úÏù∏ÏßÄ Í∞ÑÎã®Ìïú Ìï®ÏàòÎ•º Ïù¥Ïö©Ìï¥ ÌôïÏù∏Ìï¥Î≥¥Í≤†ÏäµÎãàÎã§\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGjG2j-fKbJu"
      },
      "source": [
        "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTiKccVXLrvx"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvRPOxLCLByf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c9a962-e033-44b6-93f9-a409808f8d52"
      },
      "source": [
        "print(f\"Word embedding parameter Í∞úÏàò: {count_parameters(model.encoder)}\")\n",
        "print(f\"RNN parameter Í∞úÏàò: {count_parameters(model.rnn)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word embedding parameter Í∞úÏàò: 6655600\n",
            "RNN parameter Í∞úÏàò: 890880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlUFvgTNM1Od"
      },
      "source": [
        "```\n",
        "üí° RNN parameter, Word embedding parameter Í∞úÏàòÎ•º ÎπÑÍµêÌï¥Î≥¥Î©¥ word embedding parameterÏùò Í∞úÏàòÍ∞Ä RNN Î™®Îç∏Ïùò parameterÎ≥¥Îã§ ÏïïÎèÑÏ†ÅÏúºÎ°ú ÎßéÏäµÎãàÎã§.\n",
        "(parameter = ÌïôÏäµÌï† Î≥ÄÏàòÎì§)\n",
        "word embeddingÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≤ΩÏö∞ trainingÏóê ÏÇ¨Ïö©ÎêòÎäî text fileÏùò ÌÅ¨Í∏∞Í∞Ä Ïª§ÏßàÏàòÎ°ù word embedding parameterÎäî\n",
        "Îçî Ïª§ÏßÄÍ≤å ÎêòÍ≥† Ï†ÑÏ≤¥ parameter ÎåÄÎπÑ word embeddingÏù¥ Ï∞®ÏßÄÌïòÎäî ÎπÑÏ§ëÏùÄ Îß§Ïö∞ ÎÜíÏïÑÏßëÎãàÎã§.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7WfyYBrPpca"
      },
      "source": [
        "```\n",
        "‚ú® Ïù¥Îü∞ parameter ÎπÑÏ§ëÏùò ÎπÑÎåÄÏπ≠ÏÑ±ÏùÑ Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥ Ï≤òÏùåÏóêÎäî character-level tokenization Î∞©Î≤ïÏù¥ Ï£ºÎ™©ÏùÑ Î∞õÏïòÏäµÎãàÎã§.\n",
        "-> ÏôúÎÉêÎ©¥ Ïö∞Î¶¨Ïùò Î™©Ï†ÅÏùÄ word ÏûÑÎ≤†Îî©Ïù¥ ÏïÑÎãå RNN(LSTM/GRU)ÏùÑ Ïûò ÌïôÏäµÏãúÌÇ§Îäî Í≤ÉÏù¥ Ï£ºÎ™©Ï†ÅÏù¥Îã§.\n",
        "  Í∑∏Îü¨ÎÇò ÏûÑÎ≤†Îî© Ï∞®ÏõêÏóêÏÑú parameterÏùò ÏàòÍ∞Ä ÏïïÎèÑÏ†ÅÏúºÎ°ú ÎßéÎã§Î©¥ Ïù¥ÎØ∏ Ïó¨Í∏∞ÏÑú overfittingÏù¥ ÏùºÏñ¥ÎÇò Ï†úÎåÄÎ°úÎêú ÏÑ±Îä•ÏùÑ Î∞úÌúòÌïòÍ∏∞ Ïñ¥Î†µÎã§.\n",
        "  Îî∞ÎùºÏÑú Ïù¥ parameterÏùò ÏàòÎ•º RNNÏùò parameterÍ≥º ÎπÑÎì±ÌïòÍ≤å ÌòπÏùÄ Îçî Ï†ÅÍ≤å\n",
        "  Ïú†ÏßÄÌïòÍ∏∞ ÏúÑÌïú Î∞©Î≤ïÏúºÎ°ú char-level, subword-level tokenizationÏùÑ Í≥†Î†§ÌïúÎã§.\n",
        "\n",
        "Îßê Í∑∏ÎåÄÎ°ú ÌïòÎÇòÏùò Í∏ÄÏûêÎ•º Í∏∞Ï§ÄÏúºÎ°ú tokenizationÏùÑ ÌïòÎäîÍ±¥Îç∞Ïöî.\n",
        "Ïù¥Ï†Ñ ÏòàÏãúÎ•º character Í∏∞Î∞ò tokenizationÏùÑ ÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
        "\n",
        "\"I have a meal\" -> ['I', 'h', 'a', 'v', 'e', 'a', 'm', 'e', 'a', 'l']\n",
        "\"ÎÇòÎäî Î∞•ÏùÑ Î®πÎäîÎã§\" -> ['ÎÇò', 'Îäî', 'Î∞•', 'ÏùÑ', 'Î®π', 'Îäî', 'Îã§']\n",
        "\n",
        "Í∑∏Îü¨ÎÇò, character Í∏∞Î∞ò tokenization Ïó≠Ïãú ÏßÄÎÇòÏπòÍ≤å Í∏¥ sequence Í∏∏Ïù¥, ÏÑ±Îä• Ï†ÄÌïò Îì±Ïùò Î¨∏Ï†úÎ•º Í≤™ÏúºÎ©∞\n",
        "subword tokenizationÏù¥ Í∞ÅÍ¥ëÏùÑ Î∞õÍ≤å ÎêòÏóàÏäµÎãàÎã§.\n",
        "\n",
        "‚ùì word tokenization Í∏∞Î≤ïÍ≥º Íµ¨Î∂ÑÎêòÎäî subword tokenizationÏùò Ïû•Ï†êÏùÑ ÌïòÎÇòÎßå Îçî ÏÉùÍ∞ÅÌï¥Î≥ºÍπåÏöî?\n",
        "\n",
        "subword tokenizationÏùò Ïû•Ï†êÏùÄ Out-of-vocabulary (OOV) Î¨∏Ï†úÏóêÏÑú ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏûêÏú†Î°≠Îã§Îäî Í≤ÉÏûÖÎãàÎã§.\n",
        "\n",
        "ÏùºÎ∞òÏ†ÅÏúºÎ°ú subwordÎì§ÏùÄ ÏµúÏÜå Ï≤†Ïûê Îã®ÏúÑÏóêÏÑú ÌïòÎÇòÏî© Îçî Í∏¥ subwordÎ•º Ï∂îÍ∞ÄÌïòÎäî Î∞©ÏãùÏúºÎ°ú ÎßåÎì§Ïñ¥ÏßëÎãàÎã§.\n",
        "\n",
        "ÏòàÎ•º Îì§Ïñ¥, ÏòÅÏñ¥Ïùò Í≤ΩÏö∞ a~zÏùò ÏïåÌååÎ≤≥Î∂ÄÌÑ∞ ÏãúÏûëÌï¥ÏÑú ÎëêÍ∏ÄÏûê, ÏÑ∏Í∏ÄÏûê, ÎÑ§Í∏ÄÏûê subword Îì±ÏúºÎ°ú ÌôïÏû•Ìï¥ÎÇòÍ∞ÄÎ©∞\n",
        "subwordÎ•º Ï∂îÍ∞ÄÌï¥ Îã®Ïñ¥Î•º Íµ¨ÏÑ±ÌïòÍ≥† Ïù¥Î•º Î∞îÌÉïÏúºÎ°ú subword tokenizationÏùÑ ÏàòÌñâÌïòÍ∏∞ ÎïåÎ¨∏Ïóê Îã§Î•∏ Ïñ∏Ïñ¥Î•º tokenizationÌïòÏßÄ ÏïäÎäîÎã§Î©¥\n",
        "OOV Î¨∏Ï†úÏóêÏÑú ÏûêÏú†Î°≠Îã§Í≥† Î≥º Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "ÎåÄÌëúÏ†ÅÏù∏ subword tokenizationÏóê ÏÇ¨Ïö©ÎêòÎäî algorithm Ï§ë ÌïòÎÇòÏù∏ byte pair encodingÏùÄ ÏÑ†ÌÉù Í≥ºÏ†ú 3ÏóêÏÑú ÏÇ¥Ìé¥Î≥º Ïàò ÏûàÏúºÎãà Ï∞∏Í≥†Ìï¥Ï£ºÏÑ∏Ïöî !\n",
        "\n",
        "‚ú® Í∑∏Îüº Ïù¥Ï†úÎ∂ÄÌÑ∞ BERT Î™®Îç∏ÏóêÏÑú ÏÇ¨Ïö©Ìïú subword tokenization algorithmÏùÑ Ïù¥Ïö©Ìï¥ language modeling taskÎ•º ÏàòÌñâÌï¥Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "subword tokenizerÎäî transformers ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º Ïù¥Ïö©Ìï¥ ÏâΩÍ≤å Î∂àÎü¨Ïò¨ Ïàò ÏûàÏäµÎãàÎã§.\n",
        "```\n",
        "\n",
        "(Ï∞∏Í≥†5: [Huggingface: subword tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKyn3PKUuBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "41dbfc2b71d94fb4ad9bea2ac155f338",
            "65b3557f089d4d178810fc793847a5f5",
            "59d09be3fb0e4630b05cf79af6c1669f",
            "9fa2da72f9bf4653b1077ccb0cc32674",
            "3bf83eaae872444880c48f127be300e8",
            "0291d5f8937d4932a78bdfdc99546239",
            "252bf014428b45d395b9824500079c56",
            "c518d96978924da49e4d49b696b79f95",
            "25e5fdf8181d40c9bdd56c63cd02fd09",
            "5f1fe30f3d0b4ad19625729c95dedc26",
            "cb10e3ff6aa749988cfb679d5ed894b1",
            "33bd2f84bce74cd3a5951f90561da57e",
            "fc9f5b44f1324e82b0056986b5ed5835",
            "eafda655879143eca81f7ec33fb32dca",
            "77c7f01fc242444282cfeae47d3f9dd9",
            "a15333b0fa75433ea623c4d9d9caf7be",
            "ceaabbe9ba1e40649c7702854cb2593d",
            "ca7e353288b348c582324be4d4a2d28a",
            "df1008334ad74afdab0bb9fe9f889632",
            "b93d8e23b45343ddb07d3dfb7999d0ee",
            "0137c3932e9740708b0b54d0f877b3e5",
            "8e433df75af0422da616d79e8443244d",
            "bbc19d31ca3b4ce89c4d057ed4f96baf",
            "4439fcb8b23844aaae62b2c1071db439",
            "bfdd662c123d4c29b3af9b75d351ee53",
            "2c3bb738c3ee434cb437d30288a77d5f",
            "144e5faf99924bbcb435941270fb86db",
            "79b38e5b867f401cb75732c0b5007847",
            "a11ef5e6e0c94546b6d6a6296d0aea34",
            "08c854eb1a9b4e0d9f47ae2a55a47ef5",
            "49a38656f9874682a11534ef025ac85e",
            "2258afa59c9e4aa28d52e8fc0ff2cd1a",
            "c02adae90d324626b62fcc3e9b00588d"
          ]
        },
        "outputId": "42bf14c5-1b3a-4fe9-810f-f1f68cfe3d4e"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41dbfc2b71d94fb4ad9bea2ac155f338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33bd2f84bce74cd3a5951f90561da57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbc19d31ca3b4ce89c4d057ed4f96baf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwubp25xVUt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55514793-75e8-4494-ff86-08207d057ea0"
      },
      "source": [
        "# subword tokenization ÏòàÏãú\n",
        "print(tokenizer.tokenize('Natural language expert training course'))\n",
        "print(tokenizer.tokenize('Goorm X KAIST'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'expert', 'training', 'course']\n",
            "['Go', '##orm', 'X', 'K', '##A', '##IS', '##T']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLfVolP3UKos"
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()    # dictÍ∞Ä Ìï≠ÏÉÅ Ï∞∏Ï°∞Ìï† Ïàò ÏûàÍ≤å Î∂ôÏñ¥ÏûàÎäîÍµ¨ÎÇò.\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvtarB2DYiLb"
      },
      "source": [
        "```\n",
        "Í∑∏Îü¨Î©¥ Ïù¥Ï†ú Îã§Ïãú Î™®Îç∏ÏùÑ ÏÑ†Ïñ∏ÌïòÍ≥† parameterÏùò Í∞úÏàòÎ•º ÏÇ¥Ìé¥Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKqis0hY5Or"
      },
      "source": [
        "subword_corpus = Corpus('./data/wikitext-2')\n",
        "ntokens = len(subword_corpus.dictionary)\n",
        "subwordmodel = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RB4DQ-QZCBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f686f4-c7d6-4688-fad1-f257c1ce6b14"
      },
      "source": [
        "print(f\"Word embedding parameter Í∞úÏàò: {count_parameters(subwordmodel.encoder)}\")\n",
        "print(f\"RNN parameter Í∞úÏàò: {count_parameters(subwordmodel.rnn)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word embedding parameter Í∞úÏàò: 4619000\n",
            "RNN parameter Í∞úÏàò: 890880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_5y4M6k1HR6"
      },
      "source": [
        "```\n",
        "Ïù¥Ï†ÑÏóê ÎπÑÌï¥ embedding parameter Í∞úÏàòÎäî ÌôïÏó∞Ìûà Ï§ÑÏñ¥Îì§ÏóàÏäµÎãàÎã§.\n",
        "6,655,600Í∞ú -> 4,619,000Í∞ú\n",
        "\n",
        "Í∑∏Îü¨Î©¥ Ïù¥Ï†ú subword Í∏∞Î∞òÏùò Ïñ∏Ïñ¥ Î™®Îç∏ ÏÑ±Îä•ÏùÑ ÏÇ¥Ìé¥Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSdSCKvd23M"
      },
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ‚îå a g m s ‚îê\n",
        "# ‚îÇ b h n t ‚îÇ\n",
        "# ‚îÇ c i o u ‚îÇ\n",
        "# ‚îÇ d j p v ‚îÇ\n",
        "# ‚îÇ e k q w ‚îÇ\n",
        "# ‚îî f l r x ‚îò.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(subword_corpus.train, args.batch_size)\n",
        "val_data = batchify(subword_corpus.valid, eval_batch_size)\n",
        "test_data = batchify(subword_corpus.test, eval_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7iRv2rHe959"
      },
      "source": [
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiLaw_Bte_nJ"
      },
      "source": [
        "###############################################################################\n",
        "# Training code1 - define functions\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ‚îå a g m s ‚îê ‚îå b h n t ‚îê\n",
        "# ‚îî b h n t ‚îò ‚îî c i o u ‚îò\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(subword_corpus.dictionary)\n",
        "    hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(subword_corpus.dictionary)\n",
        "    hidden = model.init_hidden(args.batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        model.zero_grad()\n",
        "\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        output, hidden = model(data, hidden)\n",
        "\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "        for p in model.parameters():\n",
        "            p.data.add_(p.grad, alpha=-lr)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % args.log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / args.log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // args.bptt, lr,\n",
        "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        if args.dry_run:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6m-cdbm7PvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e30f27-d26c-48ef-93a2-e4019c63c5cc"
      },
      "source": [
        "###############################################################################\n",
        "# Training code2 - run\n",
        "###############################################################################\n",
        "\n",
        "# Loop over epochs.\n",
        "lr = args.lr\n",
        "best_val_loss = None\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "    # after load the rnn params are not a continuous chunk of memory\n",
        "    # this makes them a continuous chunk, and will speed up forward pass\n",
        "    # Currently, only rnn model supports flatten_parameters function.\n",
        "    if args.model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
        "        model.rnn.flatten_parameters()\n",
        "\n",
        "# Run on test data.\n",
        "test_loss = evaluate(test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  3.27s | valid loss 14.25 | valid ppl 1551753.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  2.92s | valid loss 15.83 | valid ppl 7525430.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  2.92s | valid loss 13.73 | valid ppl 917490.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  2.93s | valid loss 12.09 | valid ppl 178327.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  3.34s | valid loss 11.30 | valid ppl 80684.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  3.08s | valid loss 11.04 | valid ppl 62099.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 10.97 | test ppl 58216.06\n",
            "=========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpv4N8wl4w8p"
      },
      "source": [
        "### 4. ÌïôÏäµÌïú Ïñ∏Ïñ¥ Î™®Îç∏Î°ú Î¨∏Ïû• ÏÉùÏÑ±\n",
        "\n",
        "\n",
        "*   ÌïôÏäµÏù¥ ÏôÑÎ£åÎêú Î™®Îç∏ÏùÑ Î∂àÎü¨ÏôÄ random Ìïú Îã®Ïñ¥Î•º input ÏúºÎ°ú ÎÑ£Ïñ¥Ï§Ä ÌõÑ Ï†ïÌï¥ÏßÑ Í∞úÏàòÏùò Îã®Ïñ¥Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
        "*   ÏÉùÏÑ±Ìïú Î¨∏Ïû•ÏùÑ decode ÌïòÏó¨ (Ï¶â, idx2word Î•º Ïù¥Ïö©Ìï¥ id Î•º word Î°ú Î≥ÄÌôòÌïòÏó¨) generate.txt ÌååÏùºÏóê Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQjeaKjO4JAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c489af-4985-4064-b513-e0b33114f694"
      },
      "source": [
        "###############################################################################\n",
        "# Language Modeling on Wikitext-2\n",
        "#\n",
        "# This file generates new sentences sampled from the language model\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "import torch\n",
        "\n",
        "# Model parameters.\n",
        "test_args = easydict.EasyDict({\n",
        "    \"data\"      : './data/wikitext-2',  # location of data corpus\n",
        "    \"checkpoint\": './model.pt',         # model checkpoint to use\n",
        "    \"outf\"      : 'generate_.txt',       # output file for generated text\n",
        "    \"words\"     : 1000,                 # number of words to generate\n",
        "    \"seed\"      : 1111,                 # random seed\n",
        "    \"cuda\"      : True,                 # use CUDA\n",
        "    \"temperature\": 1.0,                 # temperature - higher will increase diversity\n",
        "    \"log_interval\": 100                 # reporting interval\n",
        "})\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(test_args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not test_args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if test_args.cuda else \"cpu\")\n",
        "\n",
        "if test_args.temperature < 1e-3:\n",
        "    parser.error(\"--temperature has to be greater or equal 1e-3\")\n",
        "\n",
        "with open(test_args.checkpoint, 'rb') as f:\n",
        "    model = torch.load(f).to(device)\n",
        "model.eval()\n",
        "\n",
        "# corpus = Corpus(test_args.data)\n",
        "# ntokens = len(subword_corpus.dictionary)\n",
        "\n",
        "hidden = model.init_hidden(1)\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "with open(test_args.outf, 'w') as outf:\n",
        "    with torch.no_grad():  # no tracking history\n",
        "        for i in range(test_args.words):\n",
        "            output, hidden = model(input, hidden)\n",
        "            word_weights = output.squeeze().div(test_args.temperature).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            input.fill_(word_idx)\n",
        "\n",
        "            word = subword_corpus.dictionary.idx2word[word_idx]\n",
        "\n",
        "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
        "\n",
        "            if i % test_args.log_interval == 0:\n",
        "                print('| Generated {}/{} words'.format(i, test_args.words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Generated 0/1000 words\n",
            "| Generated 100/1000 words\n",
            "| Generated 200/1000 words\n",
            "| Generated 300/1000 words\n",
            "| Generated 400/1000 words\n",
            "| Generated 500/1000 words\n",
            "| Generated 600/1000 words\n",
            "| Generated 700/1000 words\n",
            "| Generated 800/1000 words\n",
            "| Generated 900/1000 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqLfZB-1wHHK"
      },
      "source": [
        "## Reference\n",
        "[Pytorch Language Model](https://github.com/pytorch/examples/tree/master/word_language_model)\n"
      ]
    }
  ]
}